# -*- coding: utf-8 -*-
"""skin-allergy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13mEIMZRRS3TJf8wHvvx_isqq77mI-1Kq
"""

from google.colab import drive
drive.mount('/content/gdrive')

import os
os.environ['KAGGLE_CONFIG_DIR'] = "/content/gdrive/My Drive/Colab Notebooks"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/My Drive/Colab Notebooks

!kaggle datasets download -d shubhamgoel27/dermnet --force

!ls

!unzip \*.zip  && rm *.zip

!ls

import tensorflow as tf
import numpy as np
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt
from pathlib import Path
from keras.preprocessing import image

import tensorflow as tf
import numpy as np
import pandas as pd
import os
import cv2
import matplotlib.pyplot as plt
from pathlib import Path
from keras.preprocessing import image

p=Path('./train')
dirs=p.glob('*')
image_data=[]
labels=[]
categories=[]
y_label=[]
for d in dirs:
    categories.append((str(d).split('/')[-1]))
    for img_path in d.glob('*.jpg'):
        img=image.load_img(img_path)
        gray=cv2.resize(np.float32(img),(80,80))
        img_array=image.img_to_array(gray)
        image_data.append(img_array)
        labels.append((str(d).split('/')[-1]))
for i in range(len(labels)):
    y_label.append(categories.index(labels[i]))

x=np.array(image_data)/255
y=np.array(y_label)

y

from sklearn.utils import shuffle
train_data,train_label=shuffle(x,y,random_state=0)
import pickle
with open('train_skin.pickle', 'wb') as f:
    pickle.dump([train_data, train_label], f)

plt.imshow(x[3487])
print(y[3487])

#backbone = tf.keras.applications.ResNet50(input_shape=(100,100,3),weights='imagenet', include_top=False)

backbone=tf.keras.applications.VGG16(
    include_top=False, 
    weights='imagenet',
    input_shape=(80, 80, 3)
)

backbone.trainable = False

#sexy model

model = tf.keras.models.Sequential()
model.add(backbone)
model.add(tf.keras.layers.MaxPooling2D(2,2))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(250,activation='relu'))
model.add(tf.keras.layers.Dropout(0.3))
model.add(tf.keras.layers.Dense(150,activation='relu'))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Dense(50,activation='relu'))
model.add(tf.keras.layers.Dropout(0.3))
model.add(tf.keras.layers.Dense(35, activation='softmax'))


model.compile(loss='sparse_categorical_crossentropy',optimizer='adam', metrics=['acc'])


    

model.summary()

checkpoint_path = "training_2/cp-{epoch:04d}.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

# Create a callback that saves the model's weights
cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1,
                                                 period=5)


model.save_weights(checkpoint_path.format(epoch=0))

try:
    latest = tf.train.latest_checkpoint(checkpoint_dir)
    model.load_weights(latest)
except:
    pass

history = model.fit(train_data,train_label,
                    epochs=20,
                    validation_split=0.2,
                    callbacks=[cp_callback])

import matplotlib.pyplot as plt
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

pred_image=image.load_img('')
gray_pred=cv2.resize(np.float32(pred_image),(100,100))
pred_img_array=image.img_to_array(gray_pred)
pred_img_array=np.array(pred_img_array)/255
x_pred=pred_img_array.reshape((-1,100,100,3))

predicted_category=categories[np.argmax(model.predict([x_pred]))]
print(predicted_category)